{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{\\mat}[1]{\\boldsymbol {#1}}\n",
    "\\newcommand{\\mattr}[1]{\\boldsymbol {#1}^\\top}\n",
    "\\newcommand{\\matinv}[1]{\\boldsymbol {#1}^{-1}}\n",
    "\\newcommand{\\vec}[1]{\\boldsymbol {#1}}\n",
    "\\newcommand{\\vectr}[1]{\\boldsymbol {#1}^\\top}\n",
    "\\newcommand{\\rvar}[1]{\\mathrm {#1}}\n",
    "\\newcommand{\\rvec}[1]{\\boldsymbol{\\mathrm{#1}}}\n",
    "\\newcommand{\\diag}{\\mathop{\\mathrm {diag}}}\n",
    "\\newcommand{\\set}[1]{\\mathbb {#1}}\n",
    "\\newcommand{\\cset}[1]{\\mathcal{#1}}\n",
    "\\newcommand{\\norm}[1]{\\left\\lVert#1\\right\\rVert}\n",
    "\\newcommand{\\pderiv}[2]{\\frac{\\partial #1}{\\partial #2}}\n",
    "\\newcommand{\\bb}[1]{\\boldsymbol{#1}}\n",
    "\\newcommand{\\E}[2][]{\\mathbb{E}_{#1}\\left[#2\\right]}\n",
    "\\newcommand{\\ip}[3]{\\left<#1,#2\\right>_{#3}}\n",
    "\\newcommand{\\given}[]{\\,\\middle\\vert\\,}\n",
    "\\newcommand{\\DKL}[2]{\\cset{D}_{\\text{KL}}\\left(#1\\,\\Vert\\, #2\\right)}\n",
    "\\newcommand{\\grad}[]{\\nabla}\n",
    "\\newcommand{\\norm}[1]{\\left\\lVert#1\\right\\rVert}\n",
    "$$\n",
    "\n",
    "# Part 4: Summary Questions\n",
    "<a id=part4></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section contains summary questions about various topics from the course material.\n",
    "\n",
    "You can add your answers in new cells below the questions.\n",
    "\n",
    "**Notes**\n",
    "\n",
    "- Clearly mark where your answer begins, e.g. write \"**Answer:**\" in the beginning of your cell.\n",
    "- Provide a full explanation, even if the question doesn't explicitly state so. We will reduce points for partial explanations!\n",
    "- This notebook should be runnable from start to end without any errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Explain the meaning of the term \"receptive field\" in the context of CNNs."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = 'red'>\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "The receptive field is, in the context of CNNs, an area in the input space\n",
    "which some feature is affected from. When the receptive field is large the network\n",
    "can learn complicated features."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Explain and elaborate about three different ways to control the rate at which the receptive field grows from layer to layer. Compare them to each other in terms of how they combine input features."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = 'red'>\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "1. Kernel Size: kernel size make a receptive field of it's size.\n",
    "in the next layer, the receptive field size is proportional to it.\n",
    "\n",
    "2. Stride: bigger stride will cause fewer overlapping pixels\n",
    "and will result with a bigger receptive field. If the stride is too big\n",
    "there will be missing pixels. The stride is too big if it is bigger then\n",
    "the kernel size.\n",
    "\n",
    "3. Dilation: dilation is a like stride between pixels in the\n",
    "samples. Dilation $d$ with kernel of size $k$ will make the\n",
    "receptive field to be $1 + d\\cdot(k-1)$.\n",
    "The receptive will grow to d values which higher than 1.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Imagine a CNN with three convolutional layers, defined as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-18T10:23:33.575663Z",
     "iopub.status.busy": "2022-01-18T10:23:33.574300Z",
     "iopub.status.idle": "2022-01-18T10:23:34.850060Z",
     "shell.execute_reply": "2022-01-18T10:23:34.850542Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "cnn = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=3, out_channels=4, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(in_channels=4, out_channels=16, kernel_size=5, stride=2, padding=2),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(in_channels=16, out_channels=32, kernel_size=7, dilation=2, padding=3),\n",
    "    nn.ReLU(),\n",
    ")\n",
    "\n",
    "cnn(torch.rand(size=(1, 3, 1024, 1024), dtype=torch.float32)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the size (spatial extent) of the receptive field of each \"pixel\" in the output tensor?"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = 'red'>\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "MaxPool2d layers are like basic convolution layers with $dilation=1$, $kernel\\_size=2$,\n",
    "$stride=2$. Also, ReLU does not affect receptive field size.\n",
    "\n",
    "We can calculate the receptive field size of the output tensor for the Conv2d layer\n",
    "using the formula:\n",
    "\n",
    "$r_0 = \\sum_{i=1}^n(k_i -1)\\cdot d_i \\cdot \\pi_{j=1}^{j-1}s_j+1$.\n",
    "\n",
    "Where k = kernel size, d = dilation and s = stride.\n",
    "\n",
    "\n",
    "$\\Rightarrow r_0 = 1\\cdot (3-1)\\cdot 1 + 1\\cdot (2-1)\\cdot 1 + 1\\cdot (5-1)\\cdot 1\\cdot 2 + 1\\cdot (2-1)\\cdot 1\\cdot 2\\cdot 2 + 2\\cdot (7-1)\\cdot 1\\cdot 2\\cdot 2\\cdot\n",
    "  2 + 1 = 112$\n",
    "\n",
    "$\\Rightarrow r_0=112$\n",
    "\n",
    "This is the receptive field size for each output tensor's \"pixel\"."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. You have trained a CNN, where each layer $l$ is represented by the mapping $\\vec{y}_l=f_l(\\vec{x};\\vec{\\theta}_l)$, and $f_l(\\cdot;\\vec{\\theta}_l)$ is a convolutional layer (not including the activation function).\n",
    "\n",
    "  After hearing that residual networks can be made much deeper, you decide to change each layer in your network you used the following residual mapping instead $\\vec{y}_l=f_l(\\vec{x};\\vec{\\theta}_l)+\\vec{x}$, and re-train.\n",
    "\n",
    "  However, to your surprise, by visualizing the learned filters $\\vec{\\theta}_l$ you observe that the original network and the residual network produce completely different filters. Explain the reason for this."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = 'red'>\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "The original network the layers learn the true output.\n",
    "However, residual network layers learn the delta (residual) between\n",
    "$\\vec{y_l}$ and $\\vec{x}$.\n",
    "This is the reason for the difference."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **True or false**: dropout must be placed only after the activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = 'red'>\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "False.\n",
    "\n",
    "dropout layers usually placed after activation layers, however it is not\n",
    "a mandatory demand. In some cases it could be faster to place dropout before the activation\n",
    "function because some elements will be dropped."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. After applying dropout with a drop-probability of $p$, the activations are scaled by $1/(1-p)$. Prove that this scaling is required in order to maintain the value of each activation unchanged in expectation."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = 'red'>\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "The probability of an element to drop is $p$ and to no drop is $(1-p)$.\n",
    "The output $f(x)$ will be equal to $0$ with probability $p$ or equal to $x$ with probability $(1-p)$.\n",
    "\n",
    "Activation vector expectation with dropout will be $(1-p)\\cdot E$.\n",
    "\n",
    "$E$ is the expectation with no dropout.\n",
    "\n",
    "$\\Rightarrow$ scaling the activations by $1/(1-p)$ will maintain the value of each activation\n",
    "unchanged in expectation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses and Activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. You're training a an image classifier that, given an image, needs to classify it as either a dog (output 0) or a hotdog (output 1). Would you train this model with an L2 loss? if so, why? if not, demonstrate with a numerical example. What would you use instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = 'red'>\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "L2 loss is not a good loss for this task. L2 is better for regression tasks.\n",
    "For classification tasks logistic loss and cross entropy will be more suitable\n",
    "along other loss functions.\n",
    "\n",
    "For example -\n",
    "\n",
    "If the classifier identify a hotdog as a dog, then $L2\\_loss=(1-0)^2=1$.\n",
    "\n",
    "However, $cross\\_entropy\\_loss=-(0\\cdotlog(1)+1\\cdot log(0)) \\rightarrow \\infty $.\n",
    "\n",
    "We can see that the cross entropy is better for this problem."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. After months of research into the origins of climate change, you observe the following result:\n",
    "\n",
    "<center><img src=\"https://sparrowism.soc.srcf.net/home/piratesarecool4.gif\" /></center>\n",
    "\n",
    "You decide to train a cutting-edge deep neural network regression model, that will predict the global temperature based on the population of pirates in `N` locations around the globe.\n",
    "You define your model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-18T10:23:34.854297Z",
     "iopub.status.busy": "2022-01-18T10:23:34.853519Z",
     "iopub.status.idle": "2022-01-18T10:23:34.884129Z",
     "shell.execute_reply": "2022-01-18T10:23:34.884654Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "N = 42  # number of known global pirate hot spots\n",
    "H = 128\n",
    "mlpirate = nn.Sequential(\n",
    "    nn.Linear(in_features=N, out_features=H),\n",
    "    nn.Sigmoid(),\n",
    "    *[\n",
    "        nn.Linear(in_features=H, out_features=H),\n",
    "        nn.Sigmoid(),\n",
    "    ]*N,\n",
    "    nn.Linear(in_features=H, out_features=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While training your model you notice that the loss reaches a plateau after only a few iterations.\n",
    "It seems that your model is no longer training.\n",
    "What is the most likely cause?"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = 'red'>\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "It is probably because the model is has vanishing gradients.\n",
    "The network is very deep and there is no use of batch normalizations or skip connections.\n",
    "\n",
    "The network uses only sigmoid activation function. This activation function is\n",
    "bounded by $[0,1]$ and because of that gradients will vanish after N+1 multiplications."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Referring to question 2 above: A friend suggests that if you replace the `sigmoid` activations with `tanh`, it will solve your problem. Is he correct? Explain why or why not."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = 'red'>\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "The $tanh$ derivative is in the range of $[-1,1]$.\n",
    "For that reason the model will still suffer from the same problem."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Regarding the ReLU activation, state whether the following sentences are **true or false** and explain:\n",
    "    1. In a model using exclusively ReLU activations, there can be no vanishing gradients.\n",
    "    2. The gradient of ReLU is linear with its input when the input is positive.\n",
    "    3. ReLU can cause \"dead\" neurons, i.e. activations that remain at a constant value of zero."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = 'red'>\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "1. False: It is not always the case. For example if the network is very deep it could\n",
    "cause vanishing gradients.\n",
    "\n",
    "2. False: The gradient of ReLU is constant for positive input.\n",
    "Specifically, it is equal to $1$.\n",
    "\n",
    "3. True: For negative inputs ReLU will output 0.\n",
    "Therefore, activations can remain at a constant value of zero."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Explain the difference between: stochastic gradient descent (SGD), mini-batch SGD and regular gradient descent (GD)."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = 'red'>\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "GD: In each iteration the method uses all the data to\n",
    "calculate the gradient.\n",
    "\n",
    "SGD: In each iteration the method uses one data point which was not used in\n",
    "the same epoch to calculate the gradient.\n",
    "Also, SGD is faster than GD because it performs fewer calculations in each iteration\n",
    "even tough there are more iterations until convergence.\n",
    "\n",
    "mini-batch SGD: In each iteration the method uses a small batch of the data\n",
    "to calculate the gradient."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Regarding SGD and GD:\n",
    "    1. Provide at least two reasons for why SGD is used more often in practice compared to GD.\n",
    "    2. In what cases can GD not be used at all?"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = 'red'>\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "1. Reason 1: SDG is usually faster than GD. As I already explained above\n",
    "SGD is faster than GD because it performs fewer calculations in each iteration\n",
    "even tough there are more iterations until convergence.\n",
    "\n",
    "Reason 2: GD uses more memory than SGD because it loads the entire data set into the memory.\n",
    "On the other hand, SGD loads only one sample in each iteration.\n",
    "\n",
    "For this two reasons many times with large data sets it is preferred to work with SGD.\n",
    "\n",
    "Note: there is a third reason which is GD can overfit the data set.\n",
    "\n",
    "2. As I said GD needs to load all the data set into the memory so if the data set is larger than\n",
    "the memory GD cannot be used."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. You have trained a deep resnet to obtain SoTA results on ImageNet.\n",
    "While training using mini-batch SGD with a batch size of $B$, you noticed that your model converged to a loss value of $l_0$ within $n$ iterations (batches across all epochs) on average.\n",
    "Thanks to your amazing results, you secure funding for a new high-powered server with GPUs containing twice the amount of RAM.\n",
    "You're now considering to increase the mini-batch size from $B$ to $2B$.\n",
    "Would you expect the number of of iterations required to converge to $l_0$ to decrease or increase when using the new batch size? explain in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = 'red'>\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "Because the batch size is bigger then the gradient the model is calculating is more\n",
    "precise and for that reason the number of overall iterations will be smaller.\n",
    "So, We expect that the number of iterations required to converge will decrease.\n",
    "Note: because the batch size is bigger it will take longer to compute each iteration."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. For each of the following statements, state whether they're **true or false** and explain why.\n",
    "    1. When training a neural network with SGD, every epoch we perform an optimization step for each sample in our dataset.\n",
    "    2. Gradients obtained with SGD have less variance and lead to quicker convergence compared to GD.\n",
    "    3. SGD is less likely to get stuck in local minima, compared to GD.\n",
    "    4. Training  with SGD requires more memory than with GD.\n",
    "    5. Assuming appropriate learning rates, SGD is guaranteed to converge to a local minimum, while GD is guaranteed to converge to the global minimum.\n",
    "    6. Given a loss surface with a narrow ravine (high curvature in one direction): SGD with momentum will converge more quickly than Newton's method which doesn't have momentum."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = 'red'>\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "1. False, SGD takes only one random sample which has not chosen yet in the epoch\n",
    "and calculates the gradient only from it.\n",
    "\n",
    "2. False, Actually it is the other way around.\n",
    "Gradients obtained with GD have less variance and lead to quicker convergence compared to SGD.\n",
    "But, because every iteration in SGD might be faster then SGD can be faster than GD overall\n",
    "\n",
    "3. True, because SGD takes random sample to calculate gradient from it has high variance\n",
    "which will help in escaping a local minima.\n",
    "\n",
    "4. False, The opposite. GD loads all the data set to the memory, but SGD loads only one sample\n",
    "each iteration.\n",
    "\n",
    "5. False, GD is not guaranteed to converge to global minimum (or it was perfect)\n",
    "But, both guaranteed to converge to local minimum\n",
    "\n",
    "6. False, Newton's method can converge in fewer iteration because it uses the first and second order\n",
    "derivatives which sometime saves time instead of calculate only first derivative.\n",
    "Also, because the surface is curvature Newton's can even be faster.\n",
    "That is even though SGD with momentum is faster probably."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. In tutorial 5 we saw an example of bi-level optimization in the context of deep learning, by embedding an optimization problem as a layer in the network.\n",
    "    1. **True or false**: In order to train such a network, the inner optimization problem must be solved with a descent based method (such as SGD, LBFGS, etc).\n",
    "  Provide a mathematical justification for your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = 'red'>\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "False, We can minimize $f=y+dy$ without using a descent method at all."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. You have trained a neural network, where each layer $l$ is represented by the mapping $\\vec{y}_l=f_l(\\vec{x};\\vec{\\theta}_l)$ for some arbitrary parametrized functions $f_l(\\cdot;\\vec{\\theta}_l)$.\n",
    "  Unfortunately while trying to break the record for the world's deepest network, you discover that you are unable to train your network with more than $L$ layers.\n",
    "    1. Explain the concepts of \"vanishing gradients\", and \"exploding gradients\".\n",
    "    2. How can each of these problems be caused by increased depth?\n",
    "    3. Provide a numerical example demonstrating each.\n",
    "    4. Assuming your problem is either of these, how can you tell which of them it is without looking at the gradient tensor(s)?"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = 'red'>\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "1. exploding gradients - when gradients are large the learning step can be too big\n",
    "which can cause the network to miss local minimums while the gradiant\n",
    "will still continue to grow.\n",
    "\n",
    "Vanishing Gradients - when gradients are very small (close to zero) then while propagated\n",
    "through the network they can become even smaller when using the chain rule.\n",
    "The result could be a slow learning rate as the networks goes deep.\n",
    "\n",
    "2. Vanishing Gradients could happen due to chain rule and Exploding Gradients can be\n",
    "the result of multiplying gradients which are bigger than 1, and then it could\n",
    "grow to infinity.\n",
    "\n",
    "3. Function f with gradient=0.5 in an n layers network can result in gradient^n\n",
    "so with relatively small n (even 30) 0.5^30 =~ 0.0000000001 which is almost zero.\n",
    "On the other hand function f with gradient=1.5 and n = 60 1.5^60 is so big is will cause\n",
    "unstable behavior\n",
    "\n",
    "4. We can know its exploading gradients by looking at the loss and see if its getting large and slow\n",
    "very fast and without control. On the other hand, if it will almost not move it will be vanishing gradient."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. You wish to train the following 2-layer MLP for a binary classification task:\n",
    "  $$\n",
    "  \\hat{y}^{(i)} =\\mat{W}_2~ \\varphi(\\mat{W}_1 \\vec{x}^{(i)}+ \\vec{b}_1) + \\vec{b}_2\n",
    "  $$\n",
    "  Your wish to minimize the in-sample loss function is defined as\n",
    "  $$\n",
    "  L_{\\mathcal{S}} = \\frac{1}{N}\\sum_{i=1}^{N}\\ell(y^{(i)},\\hat{y}^{(i)}) + \\frac{\\lambda}{2}\\left(\\norm{\\mat{W}_1}_F^2 + \\norm{\\mat{W}_2}_F^2 \\right)\n",
    "  $$\n",
    "  Where the pointwise loss is binary cross-entropy:\n",
    "  $$\n",
    "  \\ell(y, \\hat{y}) =  - y \\log(\\hat{y}) - (1-y) \\log(1-\\hat{y})\n",
    "  $$\n",
    "  \n",
    "  Write an analytic expression for the derivative of the final loss $L_{\\mathcal{S}}$ w.r.t. each of the following tensors: $\\mat{W}_1$, $\\mat{W}_2$, $\\mat{b}_1$, $\\mat{b}_2$, $\\mat{x}$."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = 'red'>\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "$\\frac{\\partial L_{\\mathcal{S}}}{\\partial \\hat y^{(i)} } = \\frac{1}{N}\n",
    "(\\frac{1-y^{(i)}}{1 - \\hat y^{(i)} }- \\frac{y^{(i)}}{\\hat y^{(i)} })\n",
    "\\Rightarrow\n",
    "\\frac{\\partial L_{\\mathcal{S}}}{\\partial \\hat y } = \\frac{1}{N}\n",
    "(\\frac{1-y}{1- \\hat y } - \\frac{y}{\\hat y } )$\n",
    "\n",
    "$\\delta W_1 =\n",
    "\\lambda W_1 + \\frac{1}{N} \\sum_{i=1}^N {\\frac{\\partial Ls}{\\partial \\hat y^{\n",
    "(i)}} \\frac{\\partial \\hat y^{(i)}}{W_1}} = \\lambda W_1 +\n",
    "\\frac{1}{N^2} \\sum_{i=1}^N {(\\frac{1-y^{(i)}}{1- \\hat y^{(i)}}- \\frac{y^{(i)\n",
    "}}{\\hat y^{(i)}}) \\cdot \\phi(W_1 x^{(i)} +\n",
    "b_1)}$\n",
    "\n",
    "$\\delta W_2 = \\lambda W_2 +\n",
    " \\frac{1}{N} \\sum_{i=1}^N {\\frac{\\partial Ls}{\\partial \\hat y^{(i)}}\n",
    " \\frac{\\partial \\hat y^{(i)}}{W_2}} =\n",
    " \\lambda W_2 + \\frac{1}{N^2} \\sum_{i=1}^N {(\\frac{1-y^{(i)}}{1- \\hat y^{(i)}}-\n",
    " \\frac{y^{(i)}}{\\hat y^{(i)}} ) \\cdot \\phi ' x^{(i)} }$\n",
    "\n",
    "\n",
    "$\\delta b_1 =\n",
    " \\frac{1}{N} \\sum_{i=1}^N {\\frac{\\partial Ls}{\\partial \\hat y^{(i)} }\n",
    " \\frac{\\partial \\hat y^{(i)} }{b_1} } =\n",
    " \\frac{1}{N^2} \\sum_{i=1}^N {(\\frac{1-y^{(i)\n",
    " }}{1- \\hat y^{(i)}}- \\frac{y^{(i)}}{\\hat y^{(i)}}) \\cdot \\phi ' W_2}\n",
    "$\n",
    "\n",
    "$\\delta b_2 =\n",
    " \\frac{1}{N} \\sum_{i=1}^N {\\frac{\\partial Ls}{\\partial \\hat y^{(i)} }\n",
    " \\frac{\\partial \\hat y^{(i)} }{b_2} } =\n",
    " \\frac{1}{N^2} \\sum_{i=1}^N {(\\frac{1-y^{(i)\n",
    " }}{1- \\hat y^{(i)}}- \\frac{y^{(i)}}{\\hat y^{(i)}})}\n",
    "$\n",
    "\n",
    "$\\delta x =\n",
    " \\frac{1}{N} \\sum_{i=1}^N {\\frac{\\partial Ls}{\\partial \\hat y^{(i)} }\n",
    " \\frac{\\partial \\hat y^{(i)} }{\\partial x} } =\n",
    " \\frac{1}{N^2} \\sum_{i=1}^N {(\\frac{1-y^{(i)\n",
    " }}{1- \\hat y^{(i)}}- \\frac{y^{(i)}}{\\hat y^{(i)}}) \\cdot \\phi ' W_2 W_1}\n",
    "$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Given the following code snippet, implement the custom backward function `part4_affine_backward` in `hw4/answers.py` so that it passes the `assert`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-18T10:23:34.893783Z",
     "iopub.status.busy": "2022-01-18T10:23:34.892985Z",
     "iopub.status.idle": "2022-01-18T10:23:35.017838Z",
     "shell.execute_reply": "2022-01-18T10:23:35.017408Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Function\n",
    "\n",
    "from hw4.answers import part4_affine_backward\n",
    "\n",
    "N, d_in, d_out = 100, 11, 7\n",
    "dtype = torch.float64\n",
    "X = torch.rand(N, d_in, dtype=dtype)\n",
    "W = torch.rand(d_out, d_in, requires_grad=True, dtype=dtype)\n",
    "b = torch.rand(d_out, requires_grad=True, dtype=dtype)\n",
    "\n",
    "def affine(X, W, b):\n",
    "    return 0.5 * X @ W.T + b\n",
    "\n",
    "class AffineLayerFunction(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, X, W, b):\n",
    "        result = affine(X, W, b)\n",
    "        ctx.save_for_backward(X, W, b)\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return part4_affine_backward(ctx, grad_output)\n",
    "\n",
    "l1 = torch.sum(AffineLayerFunction.apply(X, W, b))\n",
    "l1.backward()\n",
    "W_grad1 = W.grad\n",
    "b_grad1 = b.grad\n",
    "\n",
    "l2 = torch.sum(affine(X, W, b))\n",
    "W.grad = b.grad = None\n",
    "l2.backward()\n",
    "W_grad2 = W.grad\n",
    "b_grad2 = b.grad\n",
    "\n",
    "assert torch.allclose(W_grad1, W_grad2)\n",
    "assert torch.allclose(b_grad1, b_grad2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Regarding word embeddings:\n",
    "    1. Explain this term and why it's used in the context of a language model.\n",
    "    2. Can a language model like the sentiment analysis example from the tutorials be trained without an embedding (i.e. trained directly on sequences of tokens)? If yes, what would be the consequence for the trained model? if no, why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = 'red'>\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "1. Word embedding is a way to represent a work with a vector which holds the semantic properties.\n",
    "With this representation we can refer to a word as a point in a space and calculate the distance\n",
    "between words.\n",
    "\n",
    "2. Yes but it might not be the best idea since each word representation will be orthogonal to each\n",
    "other and for that reason the model could not calculate distance between words.\n",
    "Also, the model can increase to be humongous"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Considering the following snippet, explain:\n",
    "    1. What does `Y` contain? why this output shape?\n",
    "    2. How you would implement `nn.Embedding` yourself using only torch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-18T10:23:35.021821Z",
     "iopub.status.busy": "2022-01-18T10:23:35.021337Z",
     "iopub.status.idle": "2022-01-18T10:23:35.191309Z",
     "shell.execute_reply": "2022-01-18T10:23:35.192511Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "X = torch.randint(low=0, high=42, size=(5, 6, 7, 8))\n",
    "embedding = nn.Embedding(num_embeddings=42, embedding_dim=42000)\n",
    "Y = embedding(X)\n",
    "print(f\"{Y.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = 'red'>\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "1. Y is containing the representation of X (word embedding).\n",
    "The embedding dimension is 42000 abd first 4 dimensions of are the same in Y and X\n",
    "becuase 5\\cdot 6\\cdot 7\\cdot 8 = 420000$ is the total dimensional embeddings for each X tokens (43)\n",
    "\n",
    "2. We can implement is using NN with 42 dimension inputs and 42000 dimension output.\n",
    "Each token will be represented at 42000 vector of zeros but one one."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Regarding truncated backpropagation through time (TBPTT) with a sequence length of $S$: State whether the following sentences are **true or false**, and explain.\n",
    "    1. TBPTT uses a modified version of the backpropagation algorithm.\n",
    "    2. To implement TBPTT we only need to limit the length of the sequence provided to the model to length $S$.\n",
    "    3. TBPTT allows the model to learn relations between input that are at most $S$ timesteps apart."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = 'red'>\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "1. True, TBPTT takes derivatives from the last S timesteps.\n",
    "This is a modified version of the backpropagation algorithm.\n",
    "\n",
    "2. False, the number of timesteps of propagation can be limited as well.\n",
    "limiting the sequence length is not needed.\n",
    "\n",
    "3. True, TBPTT takes derivatives from the last S timesteps.\n",
    "Because of that the model \"remember\" only the last S timesteps and nothing earlier."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In tutorial 7 (part 2) we learned how to use attention to perform alignment between a source and target sequence in machine translation.\n",
    "    1. Explain qualitatively what the addition of the attention mechanism between the encoder and decoder does to the hidden states that the encoder and decoder each learn to generate (for their language). How are these hidden states different from the model without attention?\n",
    "    2. After learning that self-attention is gaining popularity thanks to the shiny new transformer models, you decide to change the model from the tutorial: instead of the queries being equal to the decoder hidden states, you use self-attention, so that the keys, queries and values are all equal to the encoder's hidden states (with learned projections). What influence do you expect this will have on the learned hidden states?"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = 'red'>\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "1. The encoder hidden states make a single word, by using attention, which is the best as the next word.\n",
    "The decoder searches the best word in the sequence latent space (the most suitable) and by that\n",
    "the decoder gets feedback for the hidden state from the attenstion.\n",
    "The decoder uses only the last hidden state without attention.\n",
    "\n",
    "2. The model will generate words by using the previous words from the sentence because it will not use\n",
    "hidden state of the decoder. This will result with making sequences with sequences that contain similar\n",
    "words (meaning).\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. As we have seen, a variational autoencoder's loss is comprised of a reconstruction term and  a KL-divergence term. While training your VAE, you accidentally forgot to include the KL-divergence term.\n",
    "What would be the qualitative effect of this on:\n",
    "\n",
    "    1. Images reconstructed by the model during training ($x\\to z \\to x'$)?\n",
    "    2. Images generated by the model ($z \\to x'$)?"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = 'red'>\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "1. It will cause overfitting of the model to the input data so the input and output will\n",
    "be similar. Becuase the loss is comprised only by reconstruction term then it will not use\n",
    "KL-divergence term that tells the statistical measure of the difference between distributions.\n",
    "\n",
    "2. The opposite will happen here as the input and output will not be related.\n",
    "This will happen because the loss func won't be able to tell the relation to x because\n",
    "x does not use KL-divergence term so the model could not learn a specific distribution."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Regarding VAEs, state whether each of the following statements is **true or false**, and explain:\n",
    "    1. The latent-space distribution generated by the model for a specific input image is $\\mathcal{N}(\\vec{0},\\vec{I})$.\n",
    "    2. If we feed the same image to the encoder multiple times, then decode each result, we'll get the same reconstruction.\n",
    "    3. Since the real VAE loss term is intractable, what we actually minimize instead is it's upper bound, in the hope that the bound is tight."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = 'red'>\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "1. False, the encoder does necessarily will draw the standard distribution as it\n",
    "draws from guassian distribution.\n",
    "\n",
    "2. False, we will get each time a different reconstruction because the output images are from \n",
    "a probability distribution space.\n",
    "\n",
    "3. True, the model will produce images which are bounded by some loss if the upper bound of the\n",
    "VAE loss term will be minimized."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Regarding GANs, state whether each of the following statements is **true or false**, and explain:\n",
    "    1. Ideally, we want the generator's loss to be low, and the discriminator's loss to be high so that it's fooled well by the generator.\n",
    "    2. It's crucial to backpropagate into the generator when training the discriminator.\n",
    "    3. To generate a new image, we can sample a latent-space vector from $\\mathcal{N}(\\vec{0},\\vec{I})$.\n",
    "    4. It can be beneficial for training the generator if the discriminator is trained for a few epochs first, so that it's output isn't arbitrary.\n",
    "    5. If the generator is generating plausible images and the discriminator reaches a stable state where it has 50% accuracy (for both image types), training the generator more will further improve the generated images."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = 'red'>\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "1. False, We want both of them to have a low loss since they should improve each other.\n",
    "If the discriminator loss was high is will cause the generator to probably have a higher loss\n",
    "as well.\n",
    "\n",
    "2. False, the generator can improve from this and causing the discriminator to not be able to classify\n",
    "right. Training should be done separately.\n",
    "\n",
    "3. True, We can basically use any probabilistic distribution we want. We only need that the model will use\n",
    "only this distribution, so it will minimize the distance between the real image date set distribution and\n",
    "it's own.\n",
    "\n",
    "4. True, by doing so the discriminator will become better than the generator but not by too much.\n",
    "Because of that the generator will yield better results as the discriminator will be less bounded.\n",
    "\n",
    "5. False, the generator and discriminator should work against each other. This way they will improve\n",
    "and get better results. If only the generator will be trained it will not know how to get better as the\n",
    "discriminator can't give the generator the correct and accurate feedback."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. You have implemented a graph convolutional layer based on the following formula, for a graph with $N$ nodes:\n",
    "$$\n",
    "\\mat{Y}=\\varphi\\left( \\sum_{k=1}^{q} \\mat{\\Delta}^k \\mat{X} \\mat{\\alpha}_k + \\vec{b} \\right).\n",
    "$$\n",
    "    1. Assuming $\\mat{X}$ is the input feature matrix of shape $(N, M)$: what does $\\mat{Y}$ contain in it's rows?\n",
    "    2. Unfortunately, due to a bug in your calculation of the Laplacian matrix, you accidentally zeroed the row and column $i=j=5$ (assume more than 5 nodes in the graph).\n",
    "What would be the effect of this bug on the output of your layer, $\\mat{Y}$?"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = 'red'>\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "1. Y will contain in it's rows the embedded feature of each node's vector.\n",
    "\n",
    "2. Y will have a constant in the 5th feature of the node. This will result in that\n",
    "no node in the graph will learn the 5th feature."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. We have discussed the notion of a Receptive Field in the context of a CNN. How would you define a similar concept in the context of a GCN (i.e. a model comprised of multiple graph convolutional layers)?"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color = 'red'>\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "For each node with information from his neighbors we could construct a receptive field\n",
    "if the neighbors are no more than L hops from the node. "
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}